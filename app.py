# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tR9uxpvGmB4MR0M9vzlbT3N2YwI2XYEw
"""

# %pip install streamlit

# %pip install scikit-learn

# %pip install langchain-community

# %pip install faiss-cpu

import streamlit as st
import pandas as pd
import numpy as np
from langchain.vectorstores import FAISS
from langchain.embeddings import SentenceTransformerEmbeddings
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt
import google.generativeai as genai
from sklearn.metrics.pairwise import cosine_similarity
import os

# Configure Gemini
genai.configure(api_key="AIzaSyDDrCDI2lPBJwKQoXqS3shRnpJU6SNPVGI")
model = genai.GenerativeModel("models/gemini-2.5-pro")

# Load Data
df = pd.read_csv("C:/Users/Lenovo/OneDrive/Desktop/CareerAdvisor/skills_career(Sheet1).csv")
embedding_model = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")

# Create and save FAISS index if it doesn't exist
FAISS_INDEX_PATH = "faiss_career_index"
if not os.path.exists(FAISS_INDEX_PATH):
    print("Creating and saving FAISS index...")
    # Assuming you have a 'text' column in your DataFrame to create embeddings from
    # Replace 'Skills' with the actual column name if it's different
    texts = df['Skills'].tolist()
    vectordb = FAISS.from_texts(texts, embedding_model)
    vectordb.save_local(FAISS_INDEX_PATH)
    print("FAISS index created and saved.")
else:
    print("Loading existing FAISS index...")
    # Load FAISS index
    vectordb = FAISS.load_local(FAISS_INDEX_PATH, embedding_model, allow_dangerous_deserialization=True)
    print("FAISS index loaded.")


def generate_gemini_advice(query, docs):
    context = "\n".join([
        f"{doc.metadata['Career']}: {doc.page_content}" for doc in docs
    ])
    prompt = (
        "You're an AI career advisor.\n"
        "Based on the user's input and the context of possible careers below, suggest the most suitable careers.\n"
        "Give short descriptions and learning resources. Use bullet points.\n\n"
        f"User input: {query}\n\nContext:\n{context}"
    )
    response = model.generate_content(prompt)
    return response.text.strip()

# Streamlit UI
st.title("Skill-Based Career Advisor Chatbot")

st.markdown("Enter your skills, interests, or anything about what you like:")

user_input = st.text_area("Your input:")

if st.button("Find Careers"):
    if user_input:
        with st.spinner("Finding recommendations..."):
            results = vectordb.similarity_search(user_input, k=5)
            advice = generate_gemini_advice(user_input, results)

            st.subheader("âœ… Career Recommendations")
            st.markdown(advice)

            # Confidence scores
            embedder = SentenceTransformer("all-MiniLM-L6-v2")
            user_embedding = embedder.encode([user_input])
            doc_embeddings = embedder.encode([doc.page_content for doc in results])
            similarities = cosine_similarity(user_embedding, doc_embeddings).flatten()
            confidence_scores = np.round(similarities * 100, 2)

            st.subheader("âœ… Confidence Scores")
            for label, conf in zip([doc.metadata['Career'] for doc in results], confidence_scores):
                st.write(f"{label}: {conf}% match")

            # Pie chart
            st.subheader("ðŸ“Š Career Match Visualization")
            fig, ax = plt.subplots()
            ax.pie(confidence_scores, labels=[doc.metadata['Career'] for doc in results], autopct='%1.1f%%')
            ax.axis('equal')
            st.pyplot(fig)
    else:
        st.warning("Please enter your skills or interests.")